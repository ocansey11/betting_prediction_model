{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c1232f-9d39-4723-bcfa-bcd9cfb7d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Desktop\\Kevin Work and Study\\alxModules\\Data Science Tech Track Part 2\\ML Projects\\modules\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "\n",
    "# Add the path to the `modules` directory relative to the current working directory\n",
    "current_dir = os.getcwd()\n",
    "modules_path = os.path.abspath(os.path.join(current_dir, '../..', 'modules'))\n",
    "sys.path.append(modules_path)\n",
    "print(modules_path)\n",
    "\n",
    "# Importing necessary functions\n",
    "from db_connections import get_mysql_engine\n",
    "from sql_operations import (\n",
    "    execute_sql,\n",
    "    CREATE_COMPLETED_MATCHES_TABLE,\n",
    "    CREATE_UPCOMING_MATCHES_TABLE,\n",
    "    CREATE_CURRENT_WEEK_STANDINGS_TABLE,\n",
    "    CREATE_PREVIOUS_WEEK_STANDINGS_TABLE\n",
    ")\n",
    "\n",
    "# Database connection details\n",
    "user = '<user>'\n",
    "password = '<password>'\n",
    "host = '<host>'\n",
    "port = 3306  # Change port number if necessary\n",
    "database = '<db>'\n",
    "\n",
    "# Create a connection to the database\n",
    "engine = get_mysql_engine(user, password, host, port, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad677cea-3908-47c2-981a-973c12f9c1e6",
   "metadata": {},
   "source": [
    "Option 1\n",
    "- Create the four tables necessary to create the training and testing data.\n",
    "- After you can run the combining script files in the option 1 folder\n",
    "- This is incase you manually want to c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ddf9f50-d091-45dd-81c4-fc9ca058c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute SQL script to create Testing Table if it doesnt exist\n",
    "# engine = get_mysql_engine(user, password, host, port, database)\n",
    "# execute_sql(engine, CREATE_COMPLETED_MATCHES_TABLE)\n",
    "# execute_sql(engine, CREATE_UPCOMING_MATCHES_TABLE)\n",
    "# execute_sql(engine, CREATE_CURRENT_WEEK_STANDINGS_TABLE)\n",
    "# execute_sql(engine, CREATE_PREVIOUS_WEEK_STANDINGS_TABLE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "720bb014-544d-4244-9b8e-db9f23326073",
   "metadata": {},
   "source": [
    "Option 2\n",
    "- Use the weekly updated csv files to update your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc77e4-5c49-4d8f-9a8f-93d4383a2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had errors reading the csv files so i added this to help with the encoding.\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "        confidence = result['confidence']\n",
    "        return encoding, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dc14d9-c509-423a-983f-4cc73dae66b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: ISO-8859-1 (Confidence: 0.73)\n"
     ]
    }
   ],
   "source": [
    "# Load CSV files into DataFrames\n",
    "completed_matches_path = '../../data/completed_matches.csv'\n",
    "upcoming_matches_path = '../../data/upcoming_matches.csv'\n",
    "current_leagues_standings_path = '../../data/current_week_league_standings.csv'\n",
    "previous_league_standings_path = '../../data/previous_week_league_standings.csv'\n",
    "\n",
    "# Detect encoding for your CSV files\n",
    "encoding, confidence = detect_encoding(completed_matches_path)\n",
    "print(f\"Detected encoding: {encoding} (Confidence: {confidence})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc1c715-9299-4ecd-8479-7514a797edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv files\n",
    "completed_matches_df = pd.read_csv(completed_matches_path, encoding = 'ISO-8859-1')\n",
    "upcoming_matches_df = pd.read_csv(upcoming_matches_path , encoding = 'ISO-8859-1')\n",
    "previous_standings = pd.read_csv(current_leagues_standings_path, encoding = 'ISO-8859-1')\n",
    "current_standings = pd.read_csv(previous_league_standings_path, encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24f0c45-84e8-4ab5-a9d3-3d3800548807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert DataFrames into the database\n",
    "completed_matches_df.to_sql('completed_matches', engine, if_exists='replace', index=False)\n",
    "upcoming_matches_df.to_sql('upcoming_matches', engine, if_exists='replace', index=False)\n",
    "previous_standings.to_sql('previous_week_league_standings', engine, if_exists='replace', index=False)\n",
    "current_standings.to_sql('current_week_league_standings', engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
